{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fNN7zTKMJhV3xvTPeP_5nvgIOD8P5xkE",
      "authorship_tag": "ABX9TyM3ZCzxRYx4Slli3iHeyK4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sina-salmanpour/False_memory_PTSD/blob/main/PTSD_Flase_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvNHNzmfZ7qL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entirly Reviewing flow"
      ],
      "metadata": {
        "id": "XyTHyxMyaU61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Load and Clean Data (example for verbal PTSD)\n",
        "df = pd.read_excel('ptsd_verbal.xlsx')\n",
        "# ... (pivot, split response/RT, filter RT > 200 & < 5000, exclude negatives)\n",
        "df['group'] = 'PTSD'  # Repeat for other files, concatenate\n",
        "\n",
        "# Step 2: Aggregates\n",
        "agg_df = df.groupby(['subject', 'group', 'emotion', 'item_type']).agg(\n",
        "    rate=('response', 'mean'),  # Hit/false memory/false alarm\n",
        "    rt_mean=('rt', 'mean')     # Mean RT for yes\n",
        ").reset_index()\n",
        "\n",
        "# Step 3: Normality (Shapiro-Wilk)\n",
        "for group in agg_df['group'].unique():\n",
        "    for emotion in agg_df['emotion'].unique():\n",
        "        rt_data = agg_df[(agg_df['group'] == group) & (agg_df['emotion'] == emotion) & (agg_df['item_type'] == 'CL')]['rt_mean']\n",
        "        if len(rt_data) > 2:\n",
        "            stat, p = stats.shapiro(rt_data)\n",
        "            print(f'{group}-{emotion}: Shapiro p={p}')\n",
        "\n",
        "# Step 4: ANOVA (example for false memory rate)\n",
        "model = ols('rate ~ C(group) * C(emotion)', data=agg_df[agg_df['item_type'] == 'CL']).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "\n",
        "# Non-Parametric Alternative (Kruskal-Wallis)\n",
        "groups = [agg_df[(agg_df['group'] == g) & (agg_df['item_type'] == 'CL') & (agg_df['emotion'] == 'NT')]['rate'] for g in ['PTSD', 'Non-PTSD', 'Control']]\n",
        "stat, p = stats.kruskal(*groups)\n",
        "print(f'Kruskal NT: p={p}')\n",
        "\n",
        "# Visuals\n",
        "sns.barplot(data=agg_df[agg_df['item_type'] == 'CL'], x='emotion', y='rate', hue='group')\n",
        "plt.title('False Memory Rates')\n",
        "plt.savefig('false_memory_bar.png')  # For thesis inclusion"
      ],
      "metadata": {
        "id": "j0vMC2QWadJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "493882ea-e0c3-43a9-9488-7185104692f8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'ptsd_verbal.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-203137833.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 1: Load and Clean Data (example for verbal PTSD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ptsd_verbal.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# ... (pivot, split response/RT, filter RT > 200 & < 5000, exclude negatives)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PTSD'\u001b[0m  \u001b[0;31m# Repeat for other files, concatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ptsd_verbal.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stepping down by detail"
      ],
      "metadata": {
        "id": "blBhWc2Oaja4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### version one 1"
      ],
      "metadata": {
        "id": "vm2fHHX0asgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Libraries\n",
        "import pandas as pd  # Core for DataFrames, reading CSVs, grouping\n",
        "import numpy as np   # Numerical operations, e.g., NaN handling\n",
        "from scipy import stats  # For future normality (Shapiro-Wilk)\n",
        "import matplotlib.pyplot as plt  # Basic plotting\n",
        "import seaborn as sns  # Advanced visuals (e.g., boxplots for RT)\n",
        "import os  # File path handling\n",
        "import warnings  # Suppress warnings for clean output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility (if sampling later)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Display options for better readability\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', None)       # Auto-width\n",
        "\n",
        "print(\"Libraries imported successfully. Ready for data loading.\")"
      ],
      "metadata": {
        "id": "Ddfu6JyEV3OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1950debc-b392-4842-bab1-97ddfdefdf0a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully. Ready for data loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Simplified file paths (list instead of dict for ease; group from key)\n",
        "files = {\n",
        "    'verbal_PSTD': '/content/drive/MyDrive/AmirFarhang/ptsd_verbal.xlsx',\n",
        "    'verbal_Non-PTSD': '/content/drive/MyDrive/AmirFarhang/non_ptsd_verbal.xlsx',\n",
        "    'verbal_Control': '/content/drive/MyDrive/AmirFarhang/control_verbal.xlsx',\n",
        "    'video_PSTD': '/content/drive/MyDrive/AmirFarhang/ptsd_video.xlsx',\n",
        "    'video_Non-PTSD': '/content/drive/MyDrive/AmirFarhang/non_ptsd_visual.xlsx',\n",
        "    'video_Control': '/content/drive/MyDrive/AmirFarhang/control_video.xlsx'\n",
        "}\n",
        "\n",
        "# Function to process and save one file\n",
        "def process_file(file_path, file_key):\n",
        "    \"\"\"\n",
        "    Load XLSX, drop 'Subject' column, extract response/RT with custom logic, handle negatives/two-digit, save _modified.\n",
        "    Args:\n",
        "        file_path (str): Path to file.\n",
        "        file_key (str): 'verbal_PSTD' etc. for group/task extraction.\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed long format.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}. Skipping.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Drop 'Subject' column if exists (as per user: it's words, deleted/empty)\n",
        "    if 'Subject' in df.columns:\n",
        "        df = df.drop(columns=['Subject'])\n",
        "\n",
        "    # Extract task and group from key\n",
        "    task_type, group_name = file_key.split('_')\n",
        "\n",
        "    # Identify candidate (subject) columns (starting with 'Sub', 'SubP', etc.)\n",
        "    candidate_cols = [col for col in df.columns if str(col).startswith(('Sub', 'SubP', 'Subh', 'subh', 'subp'))]\n",
        "\n",
        "    # Other columns: 'answer' (item_type), unnamed third (emotion), etc.\n",
        "    id_vars = [col for col in df.columns if col not in candidate_cols]\n",
        "\n",
        "    # Melt to long (pivot candidates to rows)\n",
        "    df_long = pd.melt(df, id_vars=id_vars, value_vars=candidate_cols,\n",
        "                      var_name='candidate', value_name='value')\n",
        "\n",
        "    # Add group and task\n",
        "    df_long['group'] = group_name\n",
        "    df_long['task'] = task_type\n",
        "\n",
        "    # For videos: Assign emotion blocks (rows 1-26=O, etc.; use reset index for row num)\n",
        "    df_long = df_long.reset_index()  # Add row index for block assignment\n",
        "    # if task_type == 'video':\n",
        "    #     df_long['emotion'] = np.where(df_long['index'] < 26, 'O',  # 0-based index, rows 0-25 = O (1-26)\n",
        "    #                                   np.where(df_long['index'] < 51, 'NT',\n",
        "    #                                            np.where(df_long['index'] < 76, 'P', 'N')))\n",
        "\n",
        "    # # For verbal: Unnamed third column is emotion (assume column index 1, since Subject dropped; cols[0]='answer', cols[1]=emotion)\n",
        "    # else:\n",
        "    emotion_col = df.columns[1] if len(df.columns) > 1 else None  # Second col after 'answer'\n",
        "    if emotion_col:\n",
        "        df_long['emotion'] = df_long[emotion_col]\n",
        "    else:\n",
        "        df_long['emotion'] = 'Unknown'  # Fallback\n",
        "\n",
        "    # Map item_type from 'answer' (flag column)\n",
        "    if 'answer' in df_long.columns:\n",
        "        df_long['item_type'] = df_long['answer'].map({1: 'Target', 0: 'New', 'CL': 'Lure', np.nan: 'Unknown'})\n",
        "    else:\n",
        "        df_long['item_type'] = 'Unknown'\n",
        "\n",
        "\n",
        "    # Custom extract response (0/1) and rt (float in seconds)\n",
        "    def extract_response_rt(val):\n",
        "        if pd.isna(val) or (isinstance(val, (int, float)) and val < 0):\n",
        "            return np.nan, np.nan  # NA for NaN/negatives\n",
        "\n",
        "\n",
        "        val_str = str(val).replace(',', '')  # Remove commas if any (e.g., 15,757 â†’ 15757)\n",
        "        response = np.nan\n",
        "        rt = np.nan\n",
        "\n",
        "        if '.' in val_str:\n",
        "            before, after = val_str.split('.')\n",
        "\n",
        "        else:\n",
        "            before, after = val_str, '0'\n",
        "\n",
        "        # Ensure 'before' is a string before accessing its elements\n",
        "        before_str = str(before)\n",
        "\n",
        "        # Response = first digit (0 or 1)\n",
        "        if before_str and before_str[0] in '01':\n",
        "            response = int(before_str[0])\n",
        "\n",
        "\n",
        "        # RT = rest + '.' + after as float (in seconds)\n",
        "        rt_str = before_str[1:] + '.' + after if len(before_str) > 1 else '0.' + after\n",
        "        try:\n",
        "            rt = float(rt_str)\n",
        "        except ValueError:\n",
        "            rt = np.nan\n",
        "        if pd.isna(response):\n",
        "            rt = np.nan\n",
        "\n",
        "        #print(response, rt)\n",
        "        return response, rt\n",
        "\n",
        "    df_long[['response', 'rt']] = df_long.apply(lambda row: extract_response_rt(row['value']), axis=1, result_type='expand')\n",
        "\n",
        "    # Drop original 'value' and any temp cols (e.g., index)\n",
        "    df_long = df_long.drop(columns=['value', 'index'] if 'index' in df_long.columns else ['value'])\n",
        "\n",
        "    # Save _modified in same path (as .xlsx)\n",
        "    base_dir = os.path.dirname(file_path)\n",
        "    base_name = os.path.basename(file_path)\n",
        "    modified_name = base_name.replace('.xlsx', '_modified.xlsx')\n",
        "    modified_path = os.path.join(base_dir, modified_name)\n",
        "    df_long.to_excel(modified_path, index=False)\n",
        "    print(f\"Saved modified file: {modified_path}\")\n",
        "\n",
        "    return df_long\n",
        "\n",
        "# Process all files\n",
        "all_data = []\n",
        "for file_key, path in files.items():\n",
        "    processed = process_file(path, file_key)\n",
        "    if processed is not None:\n",
        "        all_data.append(processed)\n",
        "\n",
        "# Optional: Concat all for full analysis, save\n",
        "if all_data:\n",
        "    full_df = pd.concat(all_data, ignore_index=True)\n",
        "    full_df.to_excel('/content/drive/MyDrive/AmirFarhang/full_processed.xlsx', index=False)\n",
        "    print(\"All files processed and full_processed saved.\")\n",
        "else:\n",
        "    print(\"No files processed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL0_SZJPG4QY",
        "outputId": "00f20fab-9510-4056-fa9b-698861591e5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved modified file: /content/drive/MyDrive/AmirFarhang/ptsd_verbal_modified.xlsx\n",
            "Saved modified file: /content/drive/MyDrive/AmirFarhang/non_ptsd_verbal_modified.xlsx\n",
            "Saved modified file: /content/drive/MyDrive/AmirFarhang/control_verbal_modified.xlsx\n",
            "Saved modified file: /content/drive/MyDrive/AmirFarhang/ptsd_video_modified.xlsx\n",
            "Saved modified file: /content/drive/MyDrive/AmirFarhang/non_ptsd_visual_modified.xlsx\n",
            "Saved modified file: /content/drive/MyDrive/AmirFarhang/control_video_modified.xlsx\n",
            "All files processed and full_processed saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load full_processed (or concatenate modified if needed)\n",
        "full_path = '/content/drive/MyDrive/AmirFarhang/full_processed.xlsx'\n",
        "df = pd.read_excel(full_path)\n",
        "\n",
        "# Filter out NaNs in response/rt for analysis (per your request)\n",
        "df = df.dropna(subset=['response', 'rt'])\n",
        "\n",
        "print(f\"Loaded {len(df)} rows post-NaN filter.\")\n",
        "\n",
        "# Aggregate per subject/group/task/emotion/item_type\n",
        "agg_df = df.groupby(['candidate', 'group', 'task', 'emotion', 'item_type']).agg(\n",
        "    n_trials=('response', 'count'),  # Valid trials\n",
        "    hit_rate=('response', lambda x: x[df.loc[x.index, 'item_type'] == 'Target'].mean()),  # Mean yes for Targets\n",
        "    false_memory_rate=('response', lambda x: x[df.loc[x.index, 'item_type'] == 'Lure'].mean()),  # Mean yes for Lures\n",
        "    false_alarm_rate=('response', lambda x: x[df.loc[x.index, 'item_type'] == 'New'].mean()),  # Mean yes for New\n",
        "    rt_mean=('rt', 'mean'),  # Mean RT for all yes (response==1)\n",
        "    rt_sd=('rt', 'std')      # SD for RT\n",
        ").reset_index().fillna(0)  # Fill 0 if no data (e.g., no Lures)\n",
        "\n",
        "# Descriptives: Overall means/SD by group/emotion (for rates/RT)\n",
        "descriptives = agg_df.groupby(['group', 'task', 'emotion']).agg(\n",
        "    mean_hit=('hit_rate', 'mean'),\n",
        "    sd_hit=('hit_rate', 'std'),\n",
        "    mean_false_memory=('false_memory_rate', 'mean'),\n",
        "    sd_false_memory=('false_memory_rate', 'std'),\n",
        "    mean_false_alarm=('false_alarm_rate', 'mean'),\n",
        "    sd_false_alarm=('false_alarm_rate', 'std'),\n",
        "    mean_rt=('rt_mean', 'mean'),\n",
        "    sd_rt=('rt_sd', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "print(\"Descriptives Summary:\")\n",
        "print(descriptives)\n",
        "\n",
        "# Save descriptives\n",
        "descriptives.to_excel('/content/drive/MyDrive/AmirFarhang/descriptives.xlsx', index=False)\n",
        "\n",
        "# Normality: Shapiro-Wilk on RT_mean per group/emotion/item_type (focus Lure/Target)\n",
        "norm_results = []\n",
        "for group in agg_df['group'].unique():\n",
        "    for emotion in agg_df['emotion'].unique():\n",
        "        for item in ['Lure', 'Target']:\n",
        "            rt_data = agg_df[(agg_df['group'] == group) & (agg_df['emotion'] == emotion) & (agg_df['item_type'] == item)]['rt_mean'].dropna()\n",
        "            if len(rt_data) > 2:\n",
        "                stat, p = stats.shapiro(rt_data)\n",
        "                norm_results.append({'group': group, 'emotion': emotion, 'item_type': item, 'shapiro_stat': stat, 'p_value': p, 'normal': p > 0.05})\n",
        "\n",
        "norm_df = pd.DataFrame(norm_results)\n",
        "print(\"Normality Tests:\")\n",
        "print(norm_df)\n",
        "\n",
        "norm_df.to_excel('/content/drive/MyDrive/AmirFarhang/normality_results.xlsx', index=False)\n",
        "\n",
        "# Homogeneity: Levene on RT_mean across groups for each emotion/item_type\n",
        "homog_results = []\n",
        "for emotion in agg_df['emotion'].unique():\n",
        "    for item in ['Lure', 'Target']:\n",
        "        groups_rt = [agg_df[(agg_df['group'] == g) & (agg_df['emotion'] == emotion) & (agg_df['item_type'] == item)]['rt_mean'].dropna() for g in agg_df['group'].unique()]\n",
        "        if all(len(g) > 1 for g in groups_rt):\n",
        "            stat, p = stats.levene(*groups_rt)\n",
        "            homog_results.append({'emotion': emotion, 'item_type': item, 'levene_stat': stat, 'p_value': p, 'homogeneous': p > 0.05})\n",
        "\n",
        "homog_df = pd.DataFrame(homog_results)\n",
        "print(\"Homogeneity Tests:\")\n",
        "print(homog_df)\n",
        "\n",
        "homog_df.to_excel('/content/drive/MyDrive/AmirFarhang/homogeneity_results.xlsx', index=False)\n",
        "\n",
        "# Visuals: Bar chart for false memory rates\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=agg_df[agg_df['item_type'] == 'Lure'], x='emotion', y='false_memory_rate', hue='group', errorbar='sd')\n",
        "plt.title('False Memory Rates by Group and Emotion')\n",
        "plt.ylabel('Mean False Memory Rate')\n",
        "plt.savefig('/content/drive/MyDrive/AmirFarhang/false_memory_bar.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Boxplot for RTs (Lure yes)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=agg_df[agg_df['item_type'] == 'Lure'], x='group', y='rt_mean', hue='emotion')\n",
        "plt.title('RT Distribution for Lures by Group and Emotion')\n",
        "plt.ylabel('Mean RT (ms)')\n",
        "plt.savefig('/content/drive/MyDrive/AmirFarhang/rt_boxplot.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"Initial Analysis complete. Files saved in Drive.\")"
      ],
      "metadata": {
        "id": "tnMhVTMG6TCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}